GetNCleanData
=============

This repository consists of the runanalysis.R file, ReadMe.md, CodeBook.md

==================================================================
ReadMe.md
Getting and Cleaning Data - runanalysis.R
Version 1.0
==================================================================
Sriram Subramaniam
==================================================================
Script Description
==================================================================
-The runanalysis.R is an R script that reads the training and test datasets downloaded from the coursera website of getting and cleaning data course project.
-It reads the data which consists of 561 variables(columns). The training dataset has 7352 observations(rows) and the test dataset has 2947 observations(rows).
-There are total of 30 subjects who performed 6 different activities. These different subject's ids were imported from another dataset and the activities from another dataset.
-The subjects, their activities performed and the measurements of the training and test datasets were all merged together to form a single data set.
-Each activity was referred to by an activity id which was mapped to an activity name by the activities dataset.
-A column consisting of the activity name was merged for every activity id in the merged dataset.
-Once these were all merged together, the variables(columns) were all given descriptive labels.
-The 561 variables involved different calculations out of which some were mean()[MEAN] and std()[STANDARD DEVIATION].
-Only the variables concerned with the mean() and std() were extracted out and this turned out to be a total of 66 variables.
-So at this point we have converged to a dataset from 561 variables(columns) to 66 variables(columns).
-Next task is to compute the mean of these variables for each subject and each activity.
-The 66 variables dataset was added with it the subjects id, activity id and the activity name totalling to 69 variables(columns).
-Before proceeding it was made sure all the 69 variables were given a name.
-The complete dataset was ordered by subject id's and then by activities, making it easy to compute the mean of each column.
-A for loop is processed across each subject and each of it's activity and the mean for each of the 66 columns were computed.
-The final tidy dataset was generated by using the subject id, activity id, activity name and the mean for each of the 66 columns.

==================================================================
For each record of the tidy dataset it is provided
==================================================================
- An identifier of the subject who carried out the experiment.
- An identifier of the activity and its label. 
- A 66-feature vector with time and frequency domain variables denoting the mean values of each vector